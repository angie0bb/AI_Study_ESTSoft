# NumPy, Matplotlib, EDA íŠœí† ë¦¬ì–¼

íƒœê·¸: EDA, Matplotlib, NumPy
No.: 2

# NumPy

<aside>
ğŸ“Œ ê³µì‹ë¬¸ì„œ ìœ ì € ê°€ì´ë“œ [(link)](https://numpy.org/doc/stable/user/index.html)

</aside>

- pythonì—ì„œ ë²¡í„° í™œìš©ì— ì‚¬ìš©ë˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
- listì™€ ë‹¬ë¦¬ ë³€ìˆ˜í˜• ì„¤ì •ì— ì˜ˆë¯¼í•˜ê³ , broadcasting ë“± ë²¡í„° ì—°ì‚°ì— ìœ ìš©í•œ ê¸°ëŠ¥ë“¤ ì œê³µí•œë‹¤.

## Basic Array Operations

### element-wise operations

- ê° ì›ì†Œë³„ë¡œ ì—°ì‚° ìˆ˜í–‰
- ì—°ì‚°í•˜ëŠ” ë‘ ë²¡í„°ì˜ í¬ê¸°ê°€ ë‹¤ë¥´ë©´ ìˆ˜í–‰ë˜ì§€ ì•ŠìŒ (ëª¨ì–‘ì´ ê°™ì•„ì•¼ë§Œ ìˆ˜í–‰)
- +, -, *, /, ** ë“±
- example
    
    ```bash
    data = np.array([1,2])
    ones = np.ones(2, dtype=int)
    
    print(data + ones)
    print(data * ones)
    print(data / ones)
    print(data ** 2)
    
    a = np.array([1,2,3,4])
    b = np.array([[1,2,3],[3,4,5]])
    print(a.sum())
    print(b.sum())
    print(b.sum(axis=0)) # axis ê¸°ì¤€ìœ¼ë¡œ ë”í•´ì§, ì—°ì‚° ì´í›„ í•´ë‹¹ axisëŠ” ì‚¬ë¼ì§
    print(b.sum(axis=0).shape) # 2,3 -> 3
    print(b.max(axis=1))
    print(b.mean())
    ```
    

### Broadcasting

> *The term broadcasting describes how NumPy treats **arrays with different shapes** during arithmetic operations. Subject to certain constraints, the smaller array is â€œbroadcastâ€ across the larger array so that they have compatible shapes. Broadcasting provides a means of vectorizing array operations so that looping occurs in C instead of Python. It does this without making needless copies of data and usually leads to efficient algorithm implementations. There are, however, cases where broadcasting is a bad idea because it leads to inefficient use of memory that slows computation.* [**[source]**](https://numpy.org/doc/stable/user/basics.broadcasting.html)
> 
- example
    
    ```bash
    array_example = np.array([[[1,2,3,4],
                            [4,5,6,7]],
                            [[2,3,4,5],
                            [4,5,6,7]],
                            [[3,4,5,6],
                            [4,5,6,7]]], dtype=np.float32)
    print(array_example.shape)
    print(array_example * 3)
    b = np.array([2,3]).reshape(1,2,1)
    print("\nbroadcasting\n")
    print(array_example * b)
    ```
    

### Additional point

- (4) # literal
- (4,) # tuple

# Matplotlib

- ë²¡í„° ì‹œê°í™”ë¥¼ ìœ„í•´ í™œìš©ë˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
- example
    
    ```bash
    import matplotlib.pyplot as plt
    
    x = np.linspace(0,1,100)
    y = 2 * x + 1
    
    plt.scatter(x,y,s=0.5) # ì ì„ ì°ëŠ” í•¨ìˆ˜, s: ì ì˜ í¬ê¸°
    plt.plot(x,y) # ì„ í˜• í•¨ìˆ˜
    ```
    

# EDA with Linear Model

## EDA(**Exploratory Data Analysis**)

- íƒìƒ‰ì  ë°ì´í„° ë¶„ì„
- ë¬´ì§€ì„± ì ‘ê·¼(ì—¬ëŸ¬ ì•Œê³ ë¦¬ì¦˜, ë‹¨ìˆœí•œ ëª¨ë¸ ë“±ì— ë„£ì–´ì„œ ê²°ê³¼ í™•ì¸)
- ì•„ë˜ ë„êµ¬ë“¤ë¡œ ì–´ë–¤ ëª¨ë¸ì„ ì‚¬ìš©í• ì§€ ê²°ì •
    - ì‹œê°í™”
    - êµ°ì§‘í™”
    - ì°¨ì›ì¶•ì†Œ
    - ê°€ë³ê³  ë‹¨ìˆœí•œ ëª¨ë¸

## Linear Model

- 1ì°¨ì› ì„ í˜• ëª¨ë¸: $y = ax + b$
- code example
    
    ```python
    class Linear():
        def __init__(self, a:float = 0., b:float = 0.):
            self.a = a
            self.b = b
        def forward(self, x:np.array):
            return self.a*x + self.b
        __call__ = forward # class ìì²´ë¥¼ í˜¸ì¶œí•  ìˆ˜ ìˆìŒ. í•¨ìˆ˜ì²˜ëŸ¼ ì‚¬ìš© ê°€ëŠ¥
    
    x = np.linspace(0,1,100)
    y = 2 * x + 1
    
    lin = Linear(1.5, 1.0)
    lin(x)
    ```
    

## Evaluation

- ì „ì œ
- $f$: original function
- $x = \{x_1, x_2, \dots, x_n\}\in\mathbb R^n$
- $y = \{y_1, y_2, \dots, y_n\} = \{f(x_1), f(x_2), \dots, f(x_n)\}$
- $\hat{y} = \{\hat{y}_1, \hat{y}_2, \dots, \hat{y}_n\}$: predicted value

### MSE(Mean Squared Error):

- ê° ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œ ê°’ì˜ ì°¨ì´ì˜ **ì œê³±**ì„ í‰ê· ë‚¸ ê²ƒ

$$
\operatorname{MSE}(\hat{y}, y) = \frac{1}{n}\sum_{i=1}^n (y_i - \hat{y}_i)^2
$$

### MAE(Mean Absolute Error)

- ê° ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œ ê°’ì˜ ì°¨ì´ì˜ **ì ˆëŒ€ê°’**ì„ í‰ê· ë‚¸ ê²ƒ
    
    $$
    \operatorname{MAE}(\hat{y}, y) = \frac{1}{n}\sum_{i=1}^n |y_i - \hat{y}_i|
    $$